# Ollama Configuration (Default)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b-instruct

# vLLM Configuration (Alternative for Production)
VLLM_BASE_URL=http://localhost:8000/v1
VLLM_MODEL=meta-llama/Llama-3.1-8B-Instruct

# Gemini Configuration (Fallback)
GEMINI_MODEL=gemini-flash-latest
GEMINI_API_KEY=<your_gemini_api_key>

# LLM Provider Selection (ollama, vllm, local, or gemini)
LLM_PROVIDER=local

# Search Tools API Keys
PERPLEXITY_API_KEY=<your_perplexity_api_key>
TAVILY_API_KEY=<your_tavily_api_key>

# Optional: OpenAI API Key for local OpenAI-compatible servers
# Use a dummy key if the client requires one
OPENAI_API_KEY=sk-no-key-required

# CrewAI Configuration
CREWAI_TELEMETRY_OPT_OUT=true

# Application Settings
DEBUG=true
LOG_LEVEL=INFO

# Database Configuration
DATABASE_URL=
DATABASE_NAME=hackutd_real_estate

# Local OpenAI-compatible Configuration (for any local server with OpenAI-like API)
LOCAL_BASE_URL=http://localhost:8000/v1
LOCAL_MODEL=local-model
